# 005-Reactor 模式

## epoll 高级用法——Channel

让我们来回顾一下我们是如何使用 epoll：将一个文件描述符添加到 epoll 红黑树，当该文件描述符上有事件发生时，拿到它、处理事件，这样我们每次只能拿到一个文件描述符，也就是一个 int 类型的整型值。试想，如果一个服务器同时提供不同的服务，如 HTTP、FTP 等，那么就算文件描述符上发生的事件都是可读事件，不同的连接类型也将决定不同的处理逻辑，仅仅通过一个文件描述符来区分显然会很麻烦，我们更加希望拿到关于这个文件描述符更多的信息。

在介绍 epoll 时，曾讲过 epoll_event 结构体：

```cpp
typedef union epoll_data {
  void *ptr;
  int fd;
  uint32_t u32;
  uint64_t u64;
} epoll_data_t;
struct epoll_event {
  uint32_t events;	/* Epoll events */
  epoll_data_t data;	/* User data variable */
} __EPOLL_PACKED;
```

可以看到，epoll中的 data 其实是一个 union 类型，可以储存一个指针。而通过指针，理论上我们可以指向任何一个地址块的内容，可以是一个类的对象，这样就可以将一个文件描述符封装成一个 Channel 类，一个 Channel 类自始至终只负责一个文件描述符，对不同的服务、不同的事件类型，都可以在类中进行不同的处理，而不是仅仅拿到一个 int 类型的文件描述符。

Channel 类的核心成员如下：

```cpp
class Channel{
private:
    Epoll *ep;
    int fd;
    uint32_t events;
    uint32_t revents;
    bool inEpoll;
};
```

显然每个文件描述符会被分发到一个 Epoll 类，用一个 ep 指针来指向。类中还有这个 Channel 负责的文件描述符。另外是两个事件变量，events 表示希望监听这个文件描述符的哪些事件，因为不同事件的处理方式不一样。revents 表示在 epoll 返回该 Channel 时文件描述符正在发生的事件。inEpoll 表示当前 Channel 是否已经在 epoll 红黑树中，为了注册 Channel 的时候方便区分使用 EPOLL_CTL_ADD 是 EPOLL_CTL_MOD。

接下来以 Channel 的方式使用 epoll： 新建一个 Channel 时，必须说明该 Channel 与哪个 epoll 和 fd 绑定：

```cpp
Channel *servChannel = new Channel(ep, serv_sock->getFd());
```

这时该 Channel 还没有被添加到 epoll 红黑树，因为 events 没有被设置，不会监听该 Channel 上的任何事件发生。如果我们希望监听该 Channel 上发生的读事件，需要调用一个 enableReading 函数：

```cpp
servChannel->enableReading();
```

调用这个函数后，如 Channel 不在 epoll 红黑树中，则添加，否则直接更新 Channel、打开允许读事件。enableReading 函数如下：

```cpp
void Channel::enableReading(){
    events = EPOLLIN;
    ep->updateChannel(this);
}
```

可以看到该函数做了两件事，将要监听的事件 events 设置为读事件，然后在 ep 指针指向的 Epoll 红黑树中更新该 Channel，updateChannel 函数的实现如下：

```cpp
void Epoll::updateChannel(Channel *channel){
    int fd = channel->getFd();  //拿到Channel的文件描述符
    struct epoll_event ev;
    bzero(&ev, sizeof(ev));
    ev.data.ptr = channel;
    ev.events = channel->getEvents();   //拿到Channel希望监听的事件
    if(!channel->getInEpoll()) {
        errif(epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &ev) == -1, "epoll add error");//添加Channel中的fd到epoll
        channel->setInEpoll();
    } else {
        errif(epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &ev) == -1, "epoll modify error");//已存在，则修改
    }
}
```

在使用时，我们可以通过 Epoll 类中的 poll() 函数获取当前有事件发生的 Channel：

```cpp
while(true){
    vector<Channel*> activeChannels = ep->poll();
    // activeChannels是所有有事件发生的Channel
}
```

## 服务器与事件驱动核心类登场

目前从新建socket、接受客户端连接到处理客户端事件，整个程序结构是顺序化、流程化的，我们甚至可以使用一个单一的流程图来表示整个程序。而流程化程序设计的缺点之一是不够抽象，当我们的服务器结构越来越庞大、功能越来越复杂、模块越来越多，这种顺序程序设计的思想显然是不能满足需求的。

对于服务器开发，我们需要用到更抽象的设计模式。从代码中我们可以看到，不管是接受客户端连接还是处理客户端事件，都是围绕 epoll 来编程，可以说 epoll 是整个程序的核心，服务器做的事情就是监听 epoll 上的事件，然后对不同事件类型进行不同的处理。这种以事件为核心的模式又叫事件驱动，事实上几乎所有的现代服务器都是事件驱动的。和传统的请求驱动模型有很大不同，事件的捕获、通信、处理和持久保留是解决方案的核心结构。

理解了以上的概念，就能容易理解服务器开发的两种经典模式——Reactor和Proactor模式。

[如何深刻理解Reactor和Proactor？ - 小林coding的回答 - 知乎](https://www.zhihu.com/question/26943938/answer/1856426252)

由于Linux内核系统调用的设计更加符合 Reactor 模式，所以绝大部分高性能服务器都采用 Reactor 模式进行开发，我们的服务器也使用这种模式。

接下来我们要将服务器改造成 Reactor 模式。首先我们将整个服务器抽象成一个 Server 类，这个类中有一个 main-Reactor，里面的核心是一个 EventLoop，这是一个事件循环，我们添加需要监听的事务到这个事件循环内，每次有事件发生时就会通知（在程序中返回给我们Channel），然后根据不同的描述符、事件类型进行处理（以回调函数的方式）。

EventLoop类的定义如下：

```cpp
class EventLoop {
private:
    Epoll *ep;
    bool quit;
public:
    EventLoop();
    ~EventLoop();
    void loop();
    void updateChannel(Channel*);
};
```

调用 loop() 函数可以开始事件驱动，实际上就是原来的程序中调用 epoll_wait() 函数的死循环：

```cpp
void EventLoop::loop(){
    while(!quit){
    std::vector<Channel*> chs;
        chs = ep->poll();
        for(auto it = chs.begin(); it != chs.end(); ++it){
            (*it)->handleEvent();
        }
    }
}
```

现在我们可以以这种方式来启动服务器，和 muduo 的代码已经很接近了：

```cpp
EventLoop *loop = new EventLoop();
Server *server = new Server(loop);
loop->loop();
```

服务器定义如下：

```cpp
class Server {
private:
    EventLoop *loop;
public:
    Server(EventLoop*);
    ~Server();
    void handleReadEvent(int);
    void newConnection(Socket *serv_sock);
};
```

这个版本服务器内只有一个 EventLoop，当其中有可读事件发生时，我们可以拿到该描述符对应的 Channel。在新建 Channel 时，根据 Channel 描述符的不同分别绑定了两个回调函数，newConnection() 函数被绑定到服务器 socket 上，handlrReadEvent() 被绑定到新接受的客户端 socket 上。这样如果服务器 socket 有可读事件，Channel 里的 handleEvent() 函数实际上会调用 Server 类的 newConnection() 新建连接。如果客户端 socket 有可读事件， Channel 里的 handleEvent() 函数实际上会调用 Server 类的handlrReadEvent() 响应客户端请求。

至此，我们已经抽象出了 EventLoop 和 Channel，构成了事件驱动模型。这两个类和服务器核心 Server 已经没有任何关系，经过完善后可以被任何程序复用，达到了事件驱动的设计思想，现在我们的服务器也可以看成一个最简易的 Reactor 模式服务器。

## 为服务器添加一个 Acceptor

对于每一个事件，不管提供什么样的服务，首先需要做的事都是调用 accept() 函数接受这个 TCP 连接，然后将 socket 文件描述符添加到 epoll。当这个 IO 口有事件发生的时候，再对此 TCP 连接提供相应的服务。

因此我们可以分离接受连接这一模块，添加一个 Acceptor 类，这个类有以下几个特点：

+ 类存在于事件驱动 EventLoop 类中，也就是 Reactor 模式的 main-Reactor。
+ 类中的 socket fd 就是服务器监听的 socket fd，每一个 Acceptor 对应一个socket fd。
+ 这个类也通过一个独有的 Channel 负责分发到 epoll，该 Channel 的事件处理函数 handleEvent() 会调用 Acceptor 中的接受连接函数来新建一个 TCP 连接

根据分析，Acceptor 类定义如下：

```c++
class Acceptor{
private:
    EventLoop *loop;
    Socket *sock;
    InetAddress *addr;
    Channel *acceptChannel;
public:
    Acceptor(EventLoop *_loop);
    ~Acceptor();
    void acceptConnection();
};
```

这样一来，新建连接的逻辑就在 Acceptor 类中。但逻辑上新 socket 建立后就和之前监听的服务器 socket 没有任何关系了，TCP 连接和   Acceptor 一样，拥有以上提到的三个特点，这两个类之间应该是平行关系。所以新的TCP连接应该由 Server 类来创建并管理生命周期，而不是 Acceptor。并且将这一部分代码放在 Server 类里也并没有打破服务器的通用性，因为对于所有的服务，都要使用 Acceptor 来建立连接。

为了实现这一设计，我们可以用两种方式：

+ 使用传统的虚类、虚函数来设计一个接口
+ C++11 的特性：std::function、std::bind、右值引用、std::move 等实现函数回调

虚函数使用起来比较繁琐，程序的可读性也不够清晰明朗，而std::function、std::bind等新标准的出现可以完全替代虚函数，所以本教程采用第二种方式。

首先我们需要在 Acceptor 中定义一个新建连接的回调函数：

```c++
std::function<void(Socket*)> newConnectionCallback;
```

在新建连接时，只需要调用这个回调函数：

```c++
void Acceptor::acceptConnection(){
    newConnectionCallback(sock);
}
```

而这个回调函数本身的实现在 Server 类中：

```c++
void Server::newConnection(Socket *serv_sock){
    // 接受serv_sock上的客户端连接
}
```

新建 Acceptor 时通过 std::bind 进行绑定:

```c++
acceptor = new Acceptor(loop);
std::function<void(Socket*)> cb = std::bind(&Server::newConnection, this, std::placeholders::_1);
acceptor->setNewConnectionCallback(cb);
```

这样一来，尽管我们抽象分离出了 Acceptor，新建连接的工作任然由 Server 类来完成。

## 一切皆是类，连TCP连接也不例外

对于TCP协议，三次握手新建连接后，这个连接将会一直存在，直到我们四次挥手断开连接。因此，我们也可以把TCP连接抽象成一个 Connection 类，这个类也有以下几个特点：

+ 类存在于事件驱动 EventLoop 类中，也就是 Reactor 模式的 main-Reactor。
+ 类中的 socket fd 就是客户端的 socket fd，每一个 Connection 对应一个 socket fd。
+ 每一个类的实例通过一个独有的 Channel 负责分发到 epoll，该 Channel 的事件处理函数 handleEvent() 会调用 Connection 中的事件处理函数来响应客户端请求。

Connection 类和 Acceptor 类是平行关系、十分相似，他们都直接由 Server 管理，由一个 Channel 分发到 epoll，通过回调函数处理相应事件。唯一的不同在于，Acceptor 类的处理事件函数（也就是新建连接功能）被放到了 Server 类中，具体原因在上一天的教程中已经详细说明。而 Connection 类则没有必要这么做，处理事件的逻辑应该由 Connection 类本身来完成。

另外，一个高并发服务器一般只会有一个 Acceptor 用于接受连接（也可以有多个），但可能会同时拥有成千上万个TCP连接，也就是成千上万个 Connection 类的实例，我们需要把这些 TCP 连接都保存起来。现在我们可以改写服务器核心 Server 类，定义如下：

```cpp
class Server {
private:
    EventLoop *loop;    //事件循环
    Acceptor *acceptor; //用于接受TCP连接
    std::map<int, Connection*> connections; //所有TCP连接
public:
    Server(EventLoop*);
    ~Server();

    void handleReadEvent(int);  //处理客户端请求
    void newConnection(Socket *sock);   //新建TCP连接
    void deleteConnection(Socket *sock);   //断开TCP连接
};
```

在接受连接后，服务器把该 TCP 连接保存在一个 map 中，键为该连接客户端的 socket fd，值为指向该连接的指针。该连接客户端的 socket fd 通过一个 Channel 类分发到 epoll，该 Channel 的事件处理回调函数 handleEvent() 绑定为 Connection 的业务处理函数，这样每当该连接的 socket fd 上发生事件，就会通过 Channel 调用具体连接类的业务处理函数，伪代码如下：

```cpp
void Connection::echo(int sockfd){
    // 回显sockfd发来的数据
}
Connection::Connection(EventLoop *_loop, Socket *_sock) : loop(_loop), sock(_sock), channel(nullptr){
    channel = new Channel(loop, sock->getFd()); //该连接的Channel
    std::function<void()> cb = std::bind(&Connection::echo, this, sock->getFd()); 
    channel->setCallback(cb); //绑定回调函数
    channel->enableReading(); //打开读事件监听
}
```

对于断开 TCP 连接操作，也就是销毁一个 Connection 类的实例。由于 Connection 的生命周期由 Server 进行管理，所以也应该由 Server 来删除连接。如果在 Connection 业务中需要断开连接操作，也应该和之前一样使用回调函数来实现，在 Server 新建每一个连接时绑定删除该连接的回调函数：

```cpp
Connection *conn = new Connection(loop, sock);
std::function<void(Socket*)> cb = std::bind(&Server::deleteConnection, this, std::placeholders::_1);
conn->setDeleteConnectionCallback(cb);  // 绑定删除连接的回调函数

void Server::deleteConnection(Socket * sock){
    // 删除连接
}
```
